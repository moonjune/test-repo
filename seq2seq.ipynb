{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moonjune/test-repo/blob/master/seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4ITPlCx_tL6",
        "colab_type": "code",
        "outputId": "2d29bf52-fe89-4cf9-b5fe-7bc84b4dc840",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        }
      },
      "source": [
        "!pip install tensorflow==1.12"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.12\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n",
            "\u001b[K     |████████████████████████████████| 83.1MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.0.7)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (3.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.16.3)\n",
            "Collecting tensorboard<1.13.0,>=1.12.0 (from tensorflow==1.12)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 30.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.0.9)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.7.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.12) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12) (3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12) (0.15.2)\n",
            "Installing collected packages: tensorboard, tensorflow\n",
            "  Found existing installation: tensorboard 1.13.1\n",
            "    Uninstalling tensorboard-1.13.1:\n",
            "      Successfully uninstalled tensorboard-1.13.1\n",
            "  Found existing installation: tensorflow 1.13.1\n",
            "    Uninstalling tensorflow-1.13.1:\n",
            "      Successfully uninstalled tensorflow-1.13.1\n",
            "Successfully installed tensorboard-1.12.2 tensorflow-1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYH6xM0sDB6C",
        "colab_type": "code",
        "outputId": "c64aacde-867a-4904-8d71-2b7ec3e512ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "# 임포트 된 것을 파악하여 \n",
        "import tensorflow as tf\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "from matplotlib import font_manager, rc\n",
        "\n",
        "rc('font', family='AppleGothic') #for mac\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MNxIpfHDHux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sources = [['I', 'feel', 'hungry'],\n",
        "     ['tensorflow', 'is', 'very', 'difficult'],\n",
        "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
        "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
        "# 4개 케이스, 소스\n",
        "targets = [['나는', '배가', '고프다'],\n",
        "           ['텐서플로우는', '매우', '어렵다'],\n",
        "           ['텐서플로우는', '딥러닝을', '위한', '프레임워크이다'],\n",
        "           ['텐서플로우는', '매우', '빠르게', '변화한다']]\n",
        "# 4개 케이스, 타겟"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2g1CZk8DOUx",
        "colab_type": "code",
        "outputId": "74b1c26f-9b5c-48f0-963d-b22d4496c3ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# vocabulary for sources\n",
        "s_vocab = list(set(sum(sources, [])))\n",
        "\n",
        "# s_vocab은 왜 정의하는가? 엠베딩 하기 위해 단어별를 원소로 공간을 형성\n",
        "# sum은 문자열을 합치고 있다. 조인 함수의 경우 어떻게 되는가? 안됨\n",
        "# 차원이 늘어나면 join으로 합칠 수 없나 봄. 그래서 sum을 사용하게 됨. 뒤의 []는 뭐지...; 변수의 type과 맞춰줘야 하나 봄\n",
        "# set은 중복 제거, 고유 원소로만 만드나 봄. 얘는 형태가 set 타입으로 변경됨\n",
        "# 그리고 다시 이걸 list로.. 형태를 복구시켜 줌. unique함수는 numpy나 pandas 쪽이어서 list엔 없음\n",
        "# 핵심은 문장의 형태인 단어 조합을 해체하여 단어별로 취급하고 중복을 제거하는 것 \n",
        "\n",
        "s_vocab.sort()\n",
        "s_vocab = ['<pad>'] + s_vocab\n",
        "# 거기에 패딩 원소 추가\n",
        "source2idx = {word : idx for idx, word in enumerate(s_vocab)}\n",
        "idx2source = {idx : word for idx, word in enumerate(s_vocab)}\n",
        "# 넘버링 딕셔너리\n",
        "\n",
        "pprint(source2idx)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<pad>': 0,\n",
            " 'I': 1,\n",
            " 'a': 2,\n",
            " 'changing': 3,\n",
            " 'deep': 4,\n",
            " 'difficult': 5,\n",
            " 'fast': 6,\n",
            " 'feel': 7,\n",
            " 'for': 8,\n",
            " 'framework': 9,\n",
            " 'hungry': 10,\n",
            " 'is': 11,\n",
            " 'learning': 12,\n",
            " 'tensorflow': 13,\n",
            " 'very': 14}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nXdxBIpFaoD",
        "colab_type": "code",
        "outputId": "d81a8c5c-8a84-46f6-bd30-5f5263ae59e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "# vocabularu for targets\n",
        "t_vocab = list(set(sum(targets,[])))\n",
        "t_vocab.sort()\n",
        "t_vocab = ['<pad>', '<bos>','<eos>'] + t_vocab\n",
        "target2idx = {word : idx for idx, word in enumerate(t_vocab)}\n",
        "idx2target = {idx : word for idx, word in enumerate(t_vocab)}\n",
        "#타겟도 마찬가지 처리\n",
        "\n",
        "pprint(target2idx)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<bos>': 1,\n",
            " '<eos>': 2,\n",
            " '<pad>': 0,\n",
            " '고프다': 3,\n",
            " '나는': 4,\n",
            " '딥러닝을': 5,\n",
            " '매우': 6,\n",
            " '배가': 7,\n",
            " '변화한다': 8,\n",
            " '빠르게': 9,\n",
            " '어렵다': 10,\n",
            " '위한': 11,\n",
            " '텐서플로우는': 12,\n",
            " '프레임워크이다': 13}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeTEKu9fJ0zS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#전처리 함수 정의\n",
        "def preprocess(sequences, max_len, dic, mode = 'source'):\n",
        "  assert mode in ['source','target'], 'source와 target 중에 선택해주세요'\n",
        "  # 뻑내면 나올 오류\n",
        "  \n",
        "  if mode == 'source': \n",
        "    # 소스 처리를 위한 셀(인코더)\n",
        "    s_input = list(map(lambda sentence : [dic.get(token) for token in sentence], sequences))\n",
        "    # 받는 것은 source로 문장 리스트를 받았음. \n",
        "    # 그런데 map 함수를 이용하면 리스트 내의 모든 하위 원소에 반응하는 것 같음. [문장1]이 아닌 ['단어1','단어2'] 등\n",
        "    # dic은 뒤에서 source2idx 인덱스로 들어가는 것\n",
        "    # 이 과정을 거쳐 s_input은 1차 embedding 완료\n",
        "    s_len = list(map(lambda sentence : len(sentence), s_input))\n",
        "    # s_input의 형태는 [['단어1_인덱스','단어2_인덱스'],[단어1인덱스, ..]]이럴건데..\n",
        "    # 위와 차이는 for 문이 없다는 것이다. \n",
        "    # lambda 자체가 인스턴스 함수로 애시당초 시퀀스를 변수로 받는다. 위의 식은 거기에 한번 더 for를 씌워줘서 하윗단까지 가게 한거\n",
        "    # 여기서는 투입 리스트 원소만 처리하면 되니 for 문을 쓰지 않았고 s_len은 투입받은 리스트의 원소(문장)의 길이를 세 준 것\n",
        "    s_input = pad_sequences(sequences = s_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
        "    # 다시 s_input을 조정한다. pad_sequences는 패딩 씌우는 것\n",
        "    # max_len에 맞게 10개의 길이로 통일시키기 위해 10개 이하는 뒤에 0(<pad>)을 붙여주고 넘치면 뒤를 잘라버림\n",
        "    return s_len, s_input\n",
        "    # 결과로 s_len과 s_input이 출력됨\n",
        "    \n",
        "  elif mode == 'target':\n",
        "    # 타겟 처리를 위한 셀(디코더)\n",
        "    # 투입물\n",
        "    t_input = list(map(lambda sentence : ['<bos>'] + sentence + ['<eos>'], sequences))\n",
        "    # 앞에 <bos>가 붙어서 문장의 시작을 알려서 y1이 문장의 첫 단어가 되도록 해준다. \n",
        "    # 뒤에 <eos>로 문장이 종료되었음을 선언\n",
        "    # 이것은 번역이나 대화를 위한 세팅. 디코더가 만들 문장은 인코더 셀을 다 지난 후 bos로 시작하고 eos로 종료시킴\n",
        "    t_input = list(map(lambda sentence : [dic.get(token) for token in sentence], t_input))\n",
        "    # s_input과 비슷하다. <bos>,<eos>가 추가된다.    \n",
        "    t_len = list(map(lambda sentence : len(sentence), t_input))\n",
        "    t_input = pad_sequences(sequences = t_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
        "    # <bos>,<eos>가 추가되었지만 maxlen은 동일함. 이건 나중에 살펴보자\n",
        "    # target은 번역되는 대상\n",
        "    \n",
        "    # output\n",
        "    t_output = list(map(lambda sentence : sentence + ['<eos>'], sequences))\n",
        "    # 타겟 아웃풋은 먼저 문장단위에 ['eos]만 붙여 투입한다.\n",
        "    t_output = list(map(lambda sentence : [dic.get(token) for token in sentence], t_output))\n",
        "    # target2idx를 쓰지만 역시 숫자로 이뤄진 결과를 도출한다.\n",
        "    t_output = pad_sequences(sequences = t_output, maxlen = max_len, padding = 'post', truncating = 'post')\n",
        "    \n",
        "    return t_len, t_input, t_output\n",
        "  \n",
        "  #전처리는 엠베딩 과정, 그 과정에서 <pad>등을 포함한 엠베딩을 만들고 입력 문자를 형식에 맞춰 뱉어내도록 하는 것\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLcg85C2CAeh",
        "colab_type": "code",
        "outputId": "eef61f3b-37c3-427f-d444-4b777365d695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# 소스 전처리(위의 정의 함수)\n",
        "s_max_len = 10\n",
        "s_len, s_input =preprocess(sequences = sources,\n",
        "                           max_len = s_max_len, dic = source2idx, mode = 'source')\n",
        "print(s_len, s_input)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 4, 7, 5] [[ 1  7 10  0  0  0  0  0  0  0]\n",
            " [13 11 14  5  0  0  0  0  0  0]\n",
            " [13 11  2  9  8  4 12  0  0  0]\n",
            " [13 11 14  6  3  0  0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0jTzQZjCdJ5",
        "colab_type": "code",
        "outputId": "aacfcd63-9a42-43ae-bc96-f05d7a90b182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "source": [
        "# 타겟 전처림\n",
        "t_max_len = 12\n",
        "#타겟의 길이는 12. 아마도 패딩들을 고려한 것으로 보임\n",
        "t_len, t_input, t_output = preprocess(sequences = targets,\n",
        "                                      max_len = t_max_len, dic = target2idx, mode = 'target')\n",
        "print(t_len, t_input, t_output)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5, 5, 6, 6] [[ 1  4  7  3  2  0  0  0  0  0  0  0]\n",
            " [ 1 12  6 10  2  0  0  0  0  0  0  0]\n",
            " [ 1 12  5 11 13  2  0  0  0  0  0  0]\n",
            " [ 1 12  6  9  8  2  0  0  0  0  0  0]] [[ 4  7  3  2  0  0  0  0  0  0  0  0]\n",
            " [12  6 10  2  0  0  0  0  0  0  0  0]\n",
            " [12  5 11 13  2  0  0  0  0  0  0  0]\n",
            " [12  6  9  8  2  0  0  0  0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP_DeeyMD7Sv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 하이퍼 파라미터\n",
        "epochs = 100 # 몇번 돌릴 건가\n",
        "batch_size = 4 # 한번에 장전할 문장 수(전체가 4개니..)\n",
        "learning_rate = .005 # 학습률이 학습률이지 뭐..\n",
        "total_step = epochs / batch_size \n",
        "# 이게 뭐지 대체;;; 의미적으로는 전체 배치가 도는 스텝인거고 epoch는 한 문장의 돌리는 의미인가?\n",
        "buffer_size = 100 # 얘는 아직 모르겠음 ㅎㅎ\n",
        "n_batch = buffer_size //batch_size # 배치의 개수는 버퍼 크기 나누기 배치 사이즈..\n",
        "embedding_dim = 32 # 얘는 왜 고정된 \n",
        "units = 32 # hidden size인듯\n",
        "\n",
        "#input\n",
        "data = tf.data.Dataset.from_tensor_slices((s_len, s_input, t_len, t_input, t_output))\n",
        "#데이터를 메모리에 넣어주는 기능. 0번째 차원의 크기가 동일해야 함(케이스의 수 정도)\n",
        "data = data.shuffle(buffer_size = buffer_size)\n",
        "# buffer 크기 기준으로 섞기 시작\n",
        "data = data.batch(batch_size = batch_size)\n",
        "#s_mb_len, s_mb_input, t_mb_len, t_mb_input, t_mb_output = iterator.get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80WRLuAN2Lw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gru(units):\n",
        "  # GPU가 있다면 CuDNNGRU 사용 추천(3배 빠름)\n",
        "  # 이 코드는 자동적으로 사용해줍니다.\n",
        "  if tf.test.is_gpu_available():\n",
        "    return tf.keras.laters.CuDNNGRU(units,\n",
        "                                    return_sequences = True,\n",
        "                                    return_state = True,\n",
        "                                    recurrnt_initializer = 'glorot_uniform')\n",
        "  else:\n",
        "    return tf.keras.laters.GRU(units,\n",
        "                               return_sequences = True,\n",
        "                               return_state = True,\n",
        "                               recurrnt_activation = 'sigmoid',\n",
        "                               recurrent_initializer = 'glorot_uniform')    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOqbPG-k4lZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocal_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Ecoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.laters.Embedding(vocab_size, embidding_dim)\n",
        "    self.gru = gru(self.enc_units)\n",
        "    \n",
        "  def cell(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    \n",
        "    return output, state\n",
        "  \n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOwiPXAl6NMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = gru(self.dec_units)\n",
        "    self.fc = tf.keras.laters.Dense(vocab_size)\n",
        "    \n",
        "  def call(self, x, hidden, enc_output):\n",
        "    \n",
        "    x = self.embedding(x)\n",
        "    output, seate = self.gru(x, initial_state = hidden)\n",
        "    \n",
        "    # output shape는 배치 사이즈에 *1, 히든 사이즈(32)...?\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "    \n",
        "    x = self.fc(output)\n",
        "    \n",
        "    return x, state\n",
        "  \n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.dec_units))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7chqReKDHdOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}