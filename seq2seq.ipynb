{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moonjune/test-repo/blob/master/seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4ITPlCx_tL6",
        "colab_type": "code",
        "outputId": "de089cc6-1b81-4167-9945-89a0f54565e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        }
      },
      "source": [
        "!pip install tensorflow==1.12"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.12\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n",
            "\u001b[K     |████████████████████████████████| 83.1MB 367kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.33.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.7.1)\n",
            "Collecting tensorboard<1.13.0,>=1.12.0 (from tensorflow==1.12)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 32.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.16.3)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (3.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.0.9)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.0.7)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12) (0.15.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12) (3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.12) (41.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12) (2.8.0)\n",
            "Installing collected packages: tensorboard, tensorflow\n",
            "  Found existing installation: tensorboard 1.13.1\n",
            "    Uninstalling tensorboard-1.13.1:\n",
            "      Successfully uninstalled tensorboard-1.13.1\n",
            "  Found existing installation: tensorflow 1.13.1\n",
            "    Uninstalling tensorflow-1.13.1:\n",
            "      Successfully uninstalled tensorflow-1.13.1\n",
            "Successfully installed tensorboard-1.12.2 tensorflow-1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYH6xM0sDB6C",
        "colab_type": "code",
        "outputId": "7bc5cbf0-8fbb-4616-df66-68b19be26fd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "# 임포트 된 것을 파악하여 \n",
        "import tensorflow as tf\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "from matplotlib import font_manager, rc\n",
        "\n",
        "rc('font', family='AppleGothic') #for mac\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MNxIpfHDHux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sources = [['I', 'feel', 'hungry'],\n",
        "     ['tensorflow', 'is', 'very', 'difficult'],\n",
        "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
        "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
        "# 4개 케이스, 소스\n",
        "targets = [['나는', '배가', '고프다'],\n",
        "           ['텐서플로우는', '매우', '어렵다'],\n",
        "           ['텐서플로우는', '딥러닝을', '위한', '프레임워크이다'],\n",
        "           ['텐서플로우는', '매우', '빠르게', '변화한다']]\n",
        "# 4개 케이스, 타겟"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2g1CZk8DOUx",
        "colab_type": "code",
        "outputId": "31cd6968-0826-426c-c0e5-f14920bb135b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# vocabulary for sources\n",
        "s_vocab = list(set(sum(sources, [])))\n",
        "\n",
        "# s_vocab은 왜 정의하는가? 엠베딩 하기 위해 단어별를 원소로 공간을 형성\n",
        "# sum은 문자열을 합치고 있다. 조인 함수의 경우 어떻게 되는가? 안됨\n",
        "# 차원이 늘어나면 join으로 합칠 수 없나 봄. 그래서 sum을 사용하게 됨. 뒤의 []는 뭐지...; 변수의 type과 맞춰줘야 하나 봄\n",
        "# set은 중복 제거, 고유 원소로만 만드나 봄. 얘는 형태가 set 타입으로 변경됨\n",
        "# 그리고 다시 이걸 list로.. 형태를 복구시켜 줌. unique함수는 numpy나 pandas 쪽이어서 list엔 없음\n",
        "# 핵심은 문장의 형태인 단어 조합을 해체하여 단어별로 취급하고 중복을 제거하는 것 \n",
        "\n",
        "s_vocab.sort()\n",
        "s_vocab = ['<pad>'] + s_vocab\n",
        "# 거기에 패딩 원소 추가\n",
        "source2idx = {word : idx for idx, word in enumerate(s_vocab)}\n",
        "idx2source = {idx : word for idx, word in enumerate(s_vocab)}\n",
        "# 넘버링 딕셔너리\n",
        "\n",
        "pprint(source2idx)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<pad>': 0,\n",
            " 'I': 1,\n",
            " 'a': 2,\n",
            " 'changing': 3,\n",
            " 'deep': 4,\n",
            " 'difficult': 5,\n",
            " 'fast': 6,\n",
            " 'feel': 7,\n",
            " 'for': 8,\n",
            " 'framework': 9,\n",
            " 'hungry': 10,\n",
            " 'is': 11,\n",
            " 'learning': 12,\n",
            " 'tensorflow': 13,\n",
            " 'very': 14}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nXdxBIpFaoD",
        "colab_type": "code",
        "outputId": "e2d14b8b-798d-4086-83e1-9221fdeff4e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "# vocabularu for targets\n",
        "t_vocab = list(set(sum(targets,[])))\n",
        "t_vocab.sort()\n",
        "t_vocab = ['<pad>', '<bos>','<eos>'] + t_vocab\n",
        "target2idx = {word : idx for idx, word in enumerate(t_vocab)}\n",
        "idx2target = {idx : word for idx, word in enumerate(t_vocab)}\n",
        "#타겟도 마찬가지 처리\n",
        "\n",
        "pprint(target2idx)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<bos>': 1,\n",
            " '<eos>': 2,\n",
            " '<pad>': 0,\n",
            " '고프다': 3,\n",
            " '나는': 4,\n",
            " '딥러닝을': 5,\n",
            " '매우': 6,\n",
            " '배가': 7,\n",
            " '변화한다': 8,\n",
            " '빠르게': 9,\n",
            " '어렵다': 10,\n",
            " '위한': 11,\n",
            " '텐서플로우는': 12,\n",
            " '프레임워크이다': 13}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeTEKu9fJ0zS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#전처리 함수 정의\n",
        "def preprocess(sequences, max_len, dic, mode = 'source'):\n",
        "  assert mode in ['source','target'], 'source와 target 중에 선택해주세요'\n",
        "  # 뻑내면 나올 오류\n",
        "  \n",
        "  if mode == 'source': \n",
        "    # 소스 처리를 위한 셀(인코더)\n",
        "    s_input = list(map(lambda sentence : [dic.get(token) for token in sentence], sequences))\n",
        "    # 받는 것은 source로 문장 리스트를 받았음. \n",
        "    # 그런데 map 함수를 이용하면 리스트 내의 모든 하위 원소에 반응하는 것 같음. [문장1]이 아닌 ['단어1','단어2'] 등\n",
        "    # dic은 뒤에서 source2idx 인덱스로 들어가는 것\n",
        "    # 이 과정을 거쳐 s_input은 1차 embedding 완료\n",
        "    s_len = list(map(lambda sentence : len(sentence), s_input))\n",
        "    # s_input의 형태는 [['단어1_인덱스','단어2_인덱스'],[단어1인덱스, ..]]이럴건데..\n",
        "    # 위와 차이는 for 문이 없다는 것이다. \n",
        "    # lambda 자체가 인스턴스 함수로 애시당초 시퀀스를 변수로 받는다. 위의 식은 거기에 한번 더 for를 씌워줘서 하윗단까지 가게 한거\n",
        "    # 여기서는 투입 리스트 원소만 처리하면 되니 for 문을 쓰지 않았고 s_len은 투입받은 리스트의 원소(문장)의 길이를 세 준 것\n",
        "    s_input = pad_sequences(sequences = s_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
        "    # 다시 s_input을 조정한다. pad_sequences는 패딩 씌우는 것\n",
        "    # max_len에 맞게 10개의 길이로 통일시키기 위해 10개 이하는 뒤에 0(<pad>)을 붙여주고 넘치면 뒤를 잘라버림\n",
        "    return s_len, s_input\n",
        "    # 결과로 s_len과 s_input이 출력됨\n",
        "    \n",
        "  elif mode == 'target':\n",
        "    # 타겟 처리를 위한 셀(디코더)\n",
        "    # 투입물\n",
        "    t_input = list(map(lambda sentence : ['<bos>'] + sentence + ['<eos>'], sequences))\n",
        "    # 앞에 <bos>가 붙어서 문장의 시작을 알려서 y1이 문장의 첫 단어가 되도록 해준다. \n",
        "    # 뒤에 <eos>로 문장이 종료되었음을 선언\n",
        "    # 이것은 번역이나 대화를 위한 세팅. 디코더가 만들 문장은 인코더 셀을 다 지난 후 bos로 시작하고 eos로 종료시킴\n",
        "    t_input = list(map(lambda sentence : [dic.get(token) for token in sentence], t_input))\n",
        "    # s_input과 비슷하다. <bos>,<eos>를     \n",
        "    t_len = list(map(lambda sentence : len(sentence), t_input))\n",
        "    t_input = pad_sequences(sequences = t_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
        "    \n",
        "    # output\n",
        "    t_output = list(map(lambda sentence : sentence + ['<eos>'], sequences))\n",
        "    t_output = list(map(lambda sentence : [dic.get(token) for token in sentence], t_output))\n",
        "    t_output = pad_sequences(sequences = t_output, maxlen = max_len, padding = 'post', truncating = 'post')\n",
        "    \n",
        "    return t_len, t_input, t_output\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZfOPiUi2ni1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "745acceb-16cd-451f-9676-fe86a098fd9f"
      },
      "source": [
        "s_input = list(map(lambda sentence : [source2idx.get(token) for token in sentence], sources))\n",
        "s_len = list(map(lambda sentence : len(sentence), s_input))\n",
        "print(s_len)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 4, 7, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLcg85C2CAeh",
        "colab_type": "code",
        "outputId": "80111ce3-bd4e-479d-fbf3-abbb4b9e8444",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# 소스 전처리(위의 정의 함수)\n",
        "s_max_len = 10\n",
        "s_len, s_input =preprocess(sequences = sources,\n",
        "                           max_len = s_max_len, dic = source2idx, mode = 'source')\n",
        "print(s_len, s_input)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 4, 7, 5] [[ 1  7 10  0  0  0  0  0  0  0]\n",
            " [13 11 14  5  0  0  0  0  0  0]\n",
            " [13 11  2  9  8  4 12  0  0  0]\n",
            " [13 11 14  6  3  0  0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECd0Bq7PJp3x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "d4bf9deb-2c0c-42d4-f983-dadf3fbc8347"
      },
      "source": [
        "# 소스 전처리(위의 정의 함수)\n",
        "s_max_len = 10\n",
        "s_len, s_input =preprocess(sequences = sources,\n",
        "                           max_len = s_max_len, dic = source2idx, mode = 'source')\n",
        "print(s_len, s_input)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 4, 7, 5] [[ 1  7 10  0  0  0  0  0  0  0]\n",
            " [13 11 14  5  0  0  0  0  0  0]\n",
            " [13 11  2  9  8  4 12  0  0  0]\n",
            " [13 11 14  6  3  0  0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0jTzQZjCdJ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "f1ef5b70-470b-4a9c-ee0b-bbeef052d388"
      },
      "source": [
        "# 타겟 전처림\n",
        "t_max_len = 12\n",
        "t_len, t_input, t_output = preprocess(sequences = targets,\n",
        "                                      max_len = t_max_len, dic = target2idx, mode = 'target')\n",
        "print(t_len, t_input, t_output)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5, 5, 6, 6] [[ 1  4  7  3  2  0  0  0  0  0  0  0]\n",
            " [ 1 12  6 10  2  0  0  0  0  0  0  0]\n",
            " [ 1 12  5 11 13  2  0  0  0  0  0  0]\n",
            " [ 1 12  6  9  8  2  0  0  0  0  0  0]] [[ 4  7  3  2  0  0  0  0  0  0  0  0]\n",
            " [12  6 10  2  0  0  0  0  0  0  0  0]\n",
            " [12  5 11 13  2  0  0  0  0  0  0  0]\n",
            " [12  6  9  8  2  0  0  0  0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP_DeeyMD7Sv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}