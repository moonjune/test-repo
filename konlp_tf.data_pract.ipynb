{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moonjune/test-repo/blob/master/konlp_tf.data_pract.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyHFdIPbNloP",
        "colab_type": "code",
        "outputId": "138d10de-b244-4ec2-9e81-923f7988c5cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!git clone https://github.com/NLP-kr/tensorflow-ml-nlp.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'tensorflow-ml-nlp' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1Ic356FAQoc",
        "colab_type": "code",
        "outputId": "db4dd8ef-1c97-494e-8237-0271b918024a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  tensorflow-ml-nlp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPu965unOHQG",
        "colab_type": "code",
        "outputId": "7811ee77-2cde-44ec-cd07-f881f217ee76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import os\n",
        "os.chdir('/content/tensorflow-ml-nlp')\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.Intro     3.NLP_INTRO\t\t   5.TEXT_SIM  main.png   requirements.txt\n",
            "2.NLP_PREP  4.TEXT_CLASSIFICATION  6.CHATBOT   README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LrJQIKAAfMx",
        "colab_type": "code",
        "outputId": "bd311551-c499-428a-a280-f31fa16e49ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1052
        }
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow>=1.10 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (0.24.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (3.0.3)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (0.0.1)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (1.0.1)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (1.5.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.9.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (3.2.5)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (3.6.0)\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (0.5.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 12)) (0.82)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 13)) (4.28.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10->-r requirements.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10->-r requirements.txt (line 1)) (0.2.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10->-r requirements.txt (line 1)) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10->-r requirements.txt (line 1)) (1.16.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10->-r requirements.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10->-r requirements.txt (line 1)) (1.13.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10->-r requirements.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10->-r requirements.txt (line 1)) (1.0.7)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10->-r requirements.txt (line 1)) (1.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->-r requirements.txt (line 2)) (0.21.1)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 3)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 3)) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 4)) (2.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4->-r requirements.txt (line 5)) (4.6.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from html5lib->-r requirements.txt (line 6)) (0.5.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud->-r requirements.txt (line 7)) (4.3.0)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from seaborn->-r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->-r requirements.txt (line 10)) (1.8.3)\n",
            "Requirement already satisfied: JPype1>=0.5.7 in /usr/local/lib/python3.6/dist-packages (from konlpy->-r requirements.txt (line 11)) (0.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow>=1.10->-r requirements.txt (line 1)) (41.0.1)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow>=1.10->-r requirements.txt (line 1)) (3.0.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow>=1.10->-r requirements.txt (line 1)) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow>=1.10->-r requirements.txt (line 1)) (0.15.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow>=1.10->-r requirements.txt (line 1)) (3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 2)) (0.12.5)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->wordcloud->-r requirements.txt (line 7)) (0.46)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->-r requirements.txt (line 10)) (1.9.150)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->-r requirements.txt (line 10)) (2.21.0)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->-r requirements.txt (line 10)) (2.49.0)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->-r requirements.txt (line 10)) (0.2.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->-r requirements.txt (line 10)) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.150 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->-r requirements.txt (line 10)) (1.12.150)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim->-r requirements.txt (line 10)) (2019.3.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim->-r requirements.txt (line 10)) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim->-r requirements.txt (line 10)) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim->-r requirements.txt (line 10)) (1.24.3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.150->boto3->smart-open>=1.2.1->gensim->-r requirements.txt (line 10)) (0.14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeTI6FxjAnkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf.data 실습\n",
        "import os \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras import preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxNZ2OuoF2aP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samples = ['너 오늘 이뻐 보인다',\n",
        "          '나는 오늘 기분이 더러워',\n",
        "          '끝내주는데, 좋은 일이 있나봐',\n",
        "          '나 좋은 일이 생겼어',\n",
        "          '아 오늘 진짜 짜증나',\n",
        "          '환상적인데, 정말 좋은거 같아']\n",
        "\n",
        "label = [[1],[0],[1],[1],[0],[1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-Tns7IWGiF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(samples)\n",
        "sequences = tokenizer.texts_to_sequences(samples)\n",
        "\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh8uB7OBHX1H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "2c206b69-653f-4332-a541-670640871bba"
      },
      "source": [
        "print(\"토큰화 된 배열: \", sequences)\n",
        "print(\"각 단어의 인덱스: {}\", word_index)\n",
        "print(\"라벨: \",label)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "토큰화 된 배열:  [[4, 1, 5, 6], [7, 1, 8, 9], [10, 2, 3, 11], [12, 2, 3, 13], [14, 1, 15, 16], [17, 18, 19, 20]]\n",
            "각 단어의 인덱스: {} {'오늘': 1, '좋은': 2, '일이': 3, '너': 4, '이뻐': 5, '보인다': 6, '나는': 7, '기분이': 8, '더러워': 9, '끝내주는데': 10, '있나봐': 11, '나': 12, '생겼어': 13, '아': 14, '진짜': 15, '짜증나': 16, '환상적인데': 17, '정말': 18, '좋은거': 19, '같아': 20}\n",
            "라벨:  [[1], [0], [1], [1], [0], [1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij7GfAsXGz1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((sequences, label)) # Sequenced와 label을 행 단위로 묶어줌(input target)\n",
        "iterator = dataset.make_one_shot_iterator()  # one_shot_iterator를 없애고 이따 해봐야지;\n",
        "#make_one_shot_iterator는 one-hot 인코딩을 해주는게 아니라 위에서 묶인 데이터를 하나씩 쓰도록 만들어줌\n",
        "next_data = iterator.get_next() # 이터레이터가 만들어준 순서형 데이터의 다음 데이터를 나오게 함"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKYxad6nIIbL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "0b734187-8844-43df-8e1d-9d093b735622"
      },
      "source": [
        "with tf.Session() as sess: # eager 모드는 한번 적고 난 후에 적용해볼것\n",
        "  while True: #조건 없이 while 트루라니.. \n",
        "    try:\n",
        "      print(sess.run(next_data)) # 실제 쓰이는 data는 next_data(iterator의 get_next가 적용된)\n",
        "    except tf.errors.OutOfRangeError: #안하면 무한히 가더라. 왜 for 이나 그런게 아니라 while문을? len이 안통하나? 안통하네..;\n",
        "        break"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([4, 1, 5, 6], dtype=int32), array([1], dtype=int32))\n",
            "(array([7, 1, 8, 9], dtype=int32), array([0], dtype=int32))\n",
            "(array([10,  2,  3, 11], dtype=int32), array([1], dtype=int32))\n",
            "(array([12,  2,  3, 13], dtype=int32), array([1], dtype=int32))\n",
            "(array([14,  1, 15, 16], dtype=int32), array([0], dtype=int32))\n",
            "(array([17, 18, 19, 20], dtype=int32), array([1], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaNxQ_3CTt9N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "bc36ec0e-4d02-4f97-9b64-75f0e3c6e8a4"
      },
      "source": [
        "BATCH_SIZE = 2 # 배치를 두 개로 설정\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((sequences, label))\n",
        "dataset = dataset.batch(BATCH_SIZE) # 여기서 배치 크기 적용\n",
        "iterator = dataset.make_one_shot_iterator() # 그리고 이터레이터가 2개씩 반복되도록 설정\n",
        "next_data = iterator.get_next() # 다음 요소(배치) 수령?\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  while True:\n",
        "    try:\n",
        "      print(sess.run(next_data))\n",
        "    except tf.errors.OutOfRangeError:\n",
        "      break"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([[4, 1, 5, 6],\n",
            "       [7, 1, 8, 9]], dtype=int32), array([[1],\n",
            "       [0]], dtype=int32))\n",
            "(array([[10,  2,  3, 11],\n",
            "       [12,  2,  3, 13]], dtype=int32), array([[1],\n",
            "       [1]], dtype=int32))\n",
            "(array([[14,  1, 15, 16],\n",
            "       [17, 18, 19, 20]], dtype=int32), array([[0],\n",
            "       [1]], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2gbyNqRHl9S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "43ef9495-a263-48da-a4d6-0ebea5d79ccc"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((sequences, label))\n",
        "dataset = dataset.shuffle(len(sequences)) # 얘가 섞어줌\n",
        "iterator = dataset.make_one_shot_iterator()\n",
        "next_data = iterator.get_next()\n",
        "\n",
        "with tf.Session() as sess: \n",
        "  while True:\n",
        "    try:\n",
        "      print(sess.run(next_data)) \n",
        "    except tf.errors.OutOfRangeError:\n",
        "        break"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([12,  2,  3, 13], dtype=int32), array([1], dtype=int32))\n",
            "(array([4, 1, 5, 6], dtype=int32), array([1], dtype=int32))\n",
            "(array([10,  2,  3, 11], dtype=int32), array([1], dtype=int32))\n",
            "(array([7, 1, 8, 9], dtype=int32), array([0], dtype=int32))\n",
            "(array([17, 18, 19, 20], dtype=int32), array([1], dtype=int32))\n",
            "(array([14,  1, 15, 16], dtype=int32), array([0], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Xe0XmLUHksS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "725fb6b0-857c-4582-b70f-15fec9b4f4b5"
      },
      "source": [
        "EPOCH = 2\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((sequences, label))\n",
        "dataset = dataset.repeat(EPOCH) #얘가 2배로 만들어준건가? 셔플을 어디다 두는가가 관건인거 같고..\n",
        "iterator = dataset.make_one_shot_iterator()\n",
        "next_data = iterator.get_next()\n",
        "\n",
        "with tf.Session() as sess: \n",
        "  while True:\n",
        "    try:\n",
        "      print(sess.run(next_data)) \n",
        "    except tf.errors.OutOfRangeError:\n",
        "        break"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([4, 1, 5, 6], dtype=int32), array([1], dtype=int32))\n",
            "(array([7, 1, 8, 9], dtype=int32), array([0], dtype=int32))\n",
            "(array([10,  2,  3, 11], dtype=int32), array([1], dtype=int32))\n",
            "(array([12,  2,  3, 13], dtype=int32), array([1], dtype=int32))\n",
            "(array([14,  1, 15, 16], dtype=int32), array([0], dtype=int32))\n",
            "(array([17, 18, 19, 20], dtype=int32), array([1], dtype=int32))\n",
            "(array([4, 1, 5, 6], dtype=int32), array([1], dtype=int32))\n",
            "(array([7, 1, 8, 9], dtype=int32), array([0], dtype=int32))\n",
            "(array([10,  2,  3, 11], dtype=int32), array([1], dtype=int32))\n",
            "(array([12,  2,  3, 13], dtype=int32), array([1], dtype=int32))\n",
            "(array([14,  1, 15, 16], dtype=int32), array([0], dtype=int32))\n",
            "(array([17, 18, 19, 20], dtype=int32), array([1], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUoGPOTZpJ-z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "c5e5af81-2824-4808-b5a7-0c19b9a6f286"
      },
      "source": [
        "def mapping_fn(X, Y=None): # 다른 곳에서는 lambda 함수로 대체한 케이스\n",
        "  input = {'x': X}\n",
        "  label = Y\n",
        "  return input, label\n",
        "\n",
        "# 여러 input이 나눠진 데이터로 있을 수 있음. 위의 매핑 기능을 이용하여 그런걸 다 통합할 수 있음\n",
        "# 이 것에 대해 좀 더 볼 수 있어야 겠음.. \n",
        "# 역시 위의 것은 X가 하나인 경우를 위해 만들어진 함수고, 다수 함수를 위해선 다르게 정의해야 함\n",
        "#def mapping_fn(X1, X2, ..., Y=None):\n",
        "#  input = {'x1': X1, 'x2' : } 이걸 손으로 해야하다니... 하지만 난 쪼렙이니 일단 하던거나 하자 ㅇㅇ\n",
        "#  label = Y\n",
        "#  return input, label\n",
        " \n",
        "dataset = tf.data.Dataset.from_tensor_slices((sequences, label))\n",
        "dataset = dataset.map(mapping_fn)\n",
        "iterator = dataset.make_one_shot_iterator()\n",
        "next_data = iterator.get_next()\n",
        "\n",
        "with tf.Session() as sess: \n",
        "  while True:\n",
        "    try:\n",
        "      print(sess.run(next_data)) \n",
        "    except tf.errors.OutOfRangeError:\n",
        "        break"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "({'x': array([4, 1, 5, 6], dtype=int32)}, array([1], dtype=int32))\n",
            "({'x': array([7, 1, 8, 9], dtype=int32)}, array([0], dtype=int32))\n",
            "({'x': array([10,  2,  3, 11], dtype=int32)}, array([1], dtype=int32))\n",
            "({'x': array([12,  2,  3, 13], dtype=int32)}, array([1], dtype=int32))\n",
            "({'x': array([14,  1, 15, 16], dtype=int32)}, array([0], dtype=int32))\n",
            "({'x': array([17, 18, 19, 20], dtype=int32)}, array([1], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxeqo2HSqrQn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "d0116e38-f132-49db-8451-0343030d00ee"
      },
      "source": [
        "BATCH_SIZE = 2\n",
        "EPOCH = 2\n",
        "\n",
        "def mapping_fn(X, Y=None):\n",
        "  input = {'x': X}\n",
        "  label = Y\n",
        "  return input, label\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((sequences, label))\n",
        "dataset = dataset.map(mapping_fn) # 매핑이 먼저되고\n",
        "dataset = dataset.shuffle(len(sequences)) # 셔플한 다음에\n",
        "dataset = dataset.batch(BATCH_SIZE) # 배치를 정해주고\n",
        "dataset = dataset.repeat(EPOCH) # 반복을 만들었다. \n",
        "iterator = dataset.make_one_shot_iterator()\n",
        "next_data = iterator.get_next()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  while True:\n",
        "    try:\n",
        "      print(sess.run(next_data))\n",
        "    except tf.errors.OutOfRangeError:\n",
        "      break"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "({'x': array([[ 7,  1,  8,  9],\n",
            "       [10,  2,  3, 11]], dtype=int32)}, array([[0],\n",
            "       [1]], dtype=int32))\n",
            "({'x': array([[14,  1, 15, 16],\n",
            "       [17, 18, 19, 20]], dtype=int32)}, array([[0],\n",
            "       [1]], dtype=int32))\n",
            "({'x': array([[ 4,  1,  5,  6],\n",
            "       [12,  2,  3, 13]], dtype=int32)}, array([[1],\n",
            "       [1]], dtype=int32))\n",
            "({'x': array([[10,  2,  3, 11],\n",
            "       [17, 18, 19, 20]], dtype=int32)}, array([[1],\n",
            "       [1]], dtype=int32))\n",
            "({'x': array([[14,  1, 15, 16],\n",
            "       [ 4,  1,  5,  6]], dtype=int32)}, array([[0],\n",
            "       [1]], dtype=int32))\n",
            "({'x': array([[12,  2,  3, 13],\n",
            "       [ 7,  1,  8,  9]], dtype=int32)}, array([[1],\n",
            "       [0]], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCWObbSWPok3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 마지막 셀이 보통 사용되는 기능들을 모두 넣은 데이터이다. \n",
        "# tf.data.Dataset.from_tensor_slices(x1, ... , y) 로 텐서플로에 넣기 좋게 여러 데이터 셋을 동시에 메모리에 싣는다. \n",
        "# 위의 객체로 생성된 것을 data라고 할 때, data에는 매핑(.map()), 섞기(.shuffle(길이)), 쪼개기(.batch(배치크기)), 배수복제(.repeat(횟수))를 적용한다.\n",
        "# 셔플이나 배치 쪼개기, epoch 등은 순서 한번 고려해봐도 될려나\n",
        "# tf.data는 len이 없었다. 그래서 while문을 썼었다. 추후에 같은 프로세스를 eager 모드 등으로 한번 해볼 필요가 있음"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}