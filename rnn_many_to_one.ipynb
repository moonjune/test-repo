{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_many_to_one.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moonjune/test-repo/blob/master/rnn_many_to_one.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLWSLmW5aLH_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "outputId": "b15db922-93ac-49e5-e5c6-72f35a87a47d"
      },
      "source": [
        "!pip install tensorflow==1.12"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.12\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n",
            "\u001b[K     |████████████████████████████████| 83.1MB 284kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.7.1)\n",
            "Collecting tensorboard<1.13.0,>=1.12.0 (from tensorflow==1.12)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 28.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.0.7)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.0.9)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.33.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.16.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12) (0.15.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12) (3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.12) (41.0.1)\n",
            "Installing collected packages: tensorboard, tensorflow\n",
            "  Found existing installation: tensorboard 1.13.1\n",
            "    Uninstalling tensorboard-1.13.1:\n",
            "      Successfully uninstalled tensorboard-1.13.1\n",
            "  Found existing installation: tensorflow 1.13.1\n",
            "    Uninstalling tensorflow-1.13.1:\n",
            "      Successfully uninstalled tensorflow-1.13.1\n",
            "Successfully installed tensorboard-1.12.2 tensorflow-1.12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFfo5Ki77XXE",
        "colab_type": "code",
        "outputId": "e2ed6686-fd12-4ad5-df80-b1dd8dd17846",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "%matplotlib inline\n",
        "\n",
        "print(tf.__version__)\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFPOfPFB8YrH",
        "colab_type": "code",
        "outputId": "03b22df8-b664-433a-8a25-980148d12498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# 데이터 준비. 실제 쓰이는 단어와 그 단어에 좋다 나쁘다  태깅을 한 것\n",
        "words = ['good', 'bad', 'worse', 'so good']\n",
        "y_data = [1,0,0,1]\n",
        "\n",
        "# 토큰 딕쇼너리를 만든다\n",
        "char_set = ['<pad>'] + sorted(list(set(''.join(words))))\n",
        "# 앞에 패드가 들어가는 이유는 워드 방식에선 <pad>를 한 요소로 사용하기 때문임. \n",
        "# 목적에 맞게 요소들은 추가될 것이며 추후 <seq>, <eos>등 다른 요소들도 추가 될거니 너무 신경쓰지 말 것\n",
        "# 뒤의 것은 워즈 리스트에 있는 요소들을 쌩으로 합치고(join), \n",
        "# 이걸 각 문자를 원소로 하는 집합으로 합치고(set, ',' 구분자는 여기서 생김 + 중복 제거) \n",
        "# 그걸 리스트 화 하고(list), 정렬함(sort)\n",
        "# 결과는 words 안에 있는 단어들을 스펠링과 <pad>를 원소로 하는 리스트 생성\n",
        "\n",
        "#글자 단위로 글자 세트 생성\n",
        "idx2char = {idx : char for idx, char in enumerate(char_set)}\n",
        "# enumerate는 인덱스를 붙인 시퀀스로 생성해 줌 for문과 같이 쓰여서 [인덱스, 원래 원소] 이걸 순차적으로 반복해 줌\n",
        "# :를 써도 되는지는 몰랐는데 딕셔너리 생성 시 활용\n",
        "char2idx = {char : idx for idx, char in enumerate(char_set)}\n",
        "\n",
        "print(char_set)\n",
        "print(idx2char)\n",
        "print(char2idx)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<pad>', ' ', 'a', 'b', 'd', 'e', 'g', 'o', 'r', 's', 'w']\n",
            "{0: '<pad>', 1: ' ', 2: 'a', 3: 'b', 4: 'd', 5: 'e', 6: 'g', 7: 'o', 8: 'r', 9: 's', 10: 'w'}\n",
            "{'<pad>': 0, ' ': 1, 'a': 2, 'b': 3, 'd': 4, 'e': 5, 'g': 6, 'o': 7, 'r': 8, 's': 9, 'w': 10}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eW_eNYl_FEhu",
        "colab_type": "code",
        "outputId": "93aef787-c405-4039-f4c7-19468cd9ffbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# 단어들을 만들어진 캐릭터 벡터 인덱스로 치환함\n",
        "x_data = list(map(lambda word : [char2idx.get(char) for char in word], words))\n",
        "# map 함수는 앞에는 함수, 뒤에는 인자를 받는다. \n",
        "# lambda 함수는 인스턴트 함수를 만들어 준다. 여기서 이용되는 것은 word를 받아서 word에 있는 걸 char로 받아서 전개\n",
        "# 적용되는 함수는 char2idx.get(char)인데, ()안에 인자로 key 값을 넣으면 value를 반환해주는 함수이다.\n",
        "# lambda word는 words의 스펠링 하나하나를 char로 받아 char2idx를 통해 key->value로 치환하고 그걸 리스트로 만든다\n",
        "\n",
        "x_data_len = list(map(lambda word : len(word), x_data))\n",
        "# x_data를 인자(word)로 받아서 각 단어들을 len에다 집어넣은 값 출력\n",
        "\n",
        "print(x_data)\n",
        "print(x_data_len)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6, 7, 7, 4], [3, 2, 4], [10, 7, 8, 9, 5], [9, 7, 1, 6, 7, 7, 4]]\n",
            "[4, 3, 5, 7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUCaHxE-Utu_",
        "colab_type": "code",
        "outputId": "f31fd4ee-6a76-4462-9228-16b807cb0f37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "# \n",
        "max_sequence = 10\n",
        "x_data = pad_sequences(sequences = x_data, maxlen = max_sequence,\n",
        "                      padding = 'post', truncating = 'post')\n",
        "# pad_sequences는 함수로 keras의 전처리를 위한 함수, 기초 인자는 시퀀스 데이터, 최대 시퀀스 길이, 등등..?\n",
        "# padding은 하라는 거겠지만 post나 truncate post는 무슨 뜻인지 모르겠당\n",
        "# padding: 패딩을 앞에 할 것인가(pre), 뒤로 할 것인가(post). 여기서는 뒤로 하기 위해 post\n",
        "# truncating: 넘치는 글자를 어쩔것인가? 앞을 자를 거면 'pre', 뒤를 자를 거면 'post'\n",
        "# 패딩 달아주는거. 기본 시퀀스 투입하고 최대 길이 정해주고, 패딩 어디 쌓을 건지 정하고(양옆은 없네), 넘치면 어떻게 자를건지 정해줌)\n",
        "\n",
        "print(x_data)\n",
        "print(x_data_len)\n",
        "print(y_data)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 6  7  7  4  0  0  0  0  0  0]\n",
            " [ 3  2  4  0  0  0  0  0  0  0]\n",
            " [10  7  8  9  5  0  0  0  0  0]\n",
            " [ 9  7  1  6  7  7  4  0  0  0]]\n",
            "[4, 3, 5, 7]\n",
            "[1, 0, 0, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRnf2otaGAOc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "input_dim = len(char2idx)\n",
        "# 사전의 크기\n",
        "output_dim = len(char2idx)\n",
        "# 역시 사전의 크기\n",
        "one_hot = np.eye(len(char2idx))\n",
        "# len(char2idx) * len(char2idx) 크기의 항등행렬을 만든다,\n",
        "# 이 항등행렬을 만든 이유는 각 공간들의 주소값을 주기 위해서인듯 한데..\n",
        "\n",
        "hidden_size = 10\n",
        "num_classes = 2\n",
        "\n",
        "model = Sequential()\n",
        "# Sequential 객체 선언\n",
        "model.add(layers.Embedding(input_dim = input_dim, output_dim = output_dim,\n",
        "                           trainable = False, mask_zero = True, input_length = max_sequence,\n",
        "                           embeddings_initializer = keras.initializers.Constant(one_hot)))\n",
        "# keras 특유의 레이어 쌓기. 근데 인풋과 아웃풋 차원이 이미 정해져있네..\n",
        "# rnn은 원래 한 시퀀스마다 결과를 뱉으니까 가능할 듯\n",
        "# 아니 근데 이거 다대1아니었나? 그럼 마지막에 하나만 나오는거 아닌가?\n",
        "# 그런 시비 보다는 일단 진도 빼자\n",
        "# trainable이 뭐지; one hot을 학습시키지 않는다고 하였다. (1.13에선 변경된 듯)\n",
        "# mask 제로는 연산에서 0이 된 것들을 제외한다고 하였다. mask 방법론이 적용되어 있으면 False로 0도 신경쓰게 하나..\n",
        "# embeddings_initializer = keras.initializers.Constant(one_hot)가 첫 값인데, 이걸 업데이트 하지 않겠다고 봐야하나..\n",
        "# 나중에 다시 보자\n",
        "# 위 코드를 통해 input이 될 층을 쌓은 코드\n",
        "\n",
        "\n",
        "model.add(layers.SimpleRNN(units = hidden_size))\n",
        "# rnn 층 선언\n",
        "model.add(layers.Dense(units = num_classes))\n",
        "# 마지막 층을 도출하는 것으로 유닛 수를 num_class(2 == 좋다, 나쁘다)로 정해 클래시피케이션화 시킨 것"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu196uG5k5jS",
        "colab_type": "code",
        "outputId": "d368dc21-8a48-4853-8686-25c0dae37817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 10, 11)            121       \n",
            "_________________________________________________________________\n",
            "simple_rnn_3 (SimpleRNN)     (None, 10)                220       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 22        \n",
            "=================================================================\n",
            "Total params: 363\n",
            "Trainable params: 242\n",
            "Non-trainable params: 121\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdziZfAXfmFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#모델 훈련\n",
        "def loss_fn(model, x,y):\n",
        "  return tf.losses.sparse_softmax_cross_entropy(labels = y, logits = model(x))\n",
        "#기존엔 손실함수를 수식으로 썼다면 이번엔 tf가 제공하는 손실함수를 사용, model은 위에 정의된 sequence()에 레이어 추가된 거 말함\n",
        "\n",
        "#옵티마이저 정의\n",
        "lr = 0.01\n",
        "epochs = 30\n",
        "batch_size = 2\n",
        "opt = tf.train.AdamOptimizer(learning_rate = lr)\n",
        "# 아담 옵티마이저(유명)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btNsvruRipnS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2fe10da8-89f7-4947-f626-d75b59370fde"
      },
      "source": [
        "#데이터 파이프라인 생성\n",
        "tr_dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data))\n",
        "tr_dataset = tr_dataset.shuffle(buffer_size = 4)\n",
        "tr_dataset = tr_dataset.batch(batch_size = batch_size)\n",
        "# tr_dataset은 tf.data.Dataset.from_tensor_slices로 구성된다. 일단 여러 텐서를 동시에 올릴 수 있다고 한다.\n",
        "# 큰 건 돌리지 말라고 한다. 한번에 메모리에 올려버리는 거라서\n",
        "# 일단 데이터를 한행 한행 잘라주는 거라고 한다. for 문을 대체하기 위한 걸까?\n",
        "\n",
        "# shuffle은 섞어주는 건데 일정 크기에 데이터 할당해 섞는다고 한다. 그 인수(buffer_size)가 더 커야 한다고 함\n",
        "# batch는 아는 대로 한번에 몇 개씩 넣을건지 정하는 거... 걍 뭐 그런 것이다\n",
        "\n",
        "# 간략하게 tf.data는 딥러닝을 위해 특화된 데이터 함수고 셔플이나 배치 등 데이터 변형 입력 등을 편리하게 해주는 함수로 보임  \n",
        "\n",
        "print(tr_dataset)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<DatasetV1Adapter shapes: ((?, 10), (?,)), types: (tf.int32, tf.int32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD7MYphfSamT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "e09d43e8-e02b-4fdb-ff43-1703391321c4"
      },
      "source": [
        "#훈련\n",
        "tr_loss_hist = []\n",
        "# 그래프 그리기용 히스토리\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  avg_tr_loss = 0\n",
        "  tr_step = 0\n",
        "  # avg_tr_loss 변수 값 선언 후 단계별 손실값을 더하고 스텝별로 나누는 걸로 줄여나감\n",
        "  # tr_step은 epoch랑 같은 것\n",
        "  for x_mb, y_mb in tr_dataset:\n",
        "    with tf.GradientTape() as tape:\n",
        "      tr_loss = loss_fn(model, x = x_mb, y=y_mb)\n",
        "    grads = tape.gradient(target = tr_loss, sources = model.variables)\n",
        "    opt.apply_gradients(grads_and_vars = zip(grads, model.variables))\n",
        "    avg_tr_loss += tr_loss\n",
        "    tr_step += 1\n",
        "  else:\n",
        "    avg_tr_loss /= tr_step\n",
        "    tr_loss_hist.append(avg_tr_loss)\n",
        "  # mb 뜻은 모르지만 걍 변수명으로 가고 손실함수에 앞서 정의된 rnn 모델과 x값 y값을 투입\n",
        "  # grads는 위의 gradienttape를 이용해서 tr_loss를 model.variable 값으로 미분.. \n",
        "  # model.variables는 무엇일까?\n",
        "  # 앞에서 모델은 레이어들을 가지고 있고 각 레이어의 값은 \n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    print('epoch : {:3}, tr_loss: {:.3f}'.format(epoch + 1, avg_tr_loss))\n",
        "      "
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch :   5, tr_loss: 0.248\n",
            "epoch :  10, tr_loss: 0.022\n",
            "epoch :  15, tr_loss: 0.006\n",
            "epoch :  20, tr_loss: 0.003\n",
            "epoch :  25, tr_loss: 0.002\n",
            "epoch :  30, tr_loss: 0.002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQcsPDbdg2kn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1288
        },
        "outputId": "518c4193-cb37-4be8-b71d-2c37bdf79d29"
      },
      "source": [
        "print(model.variables)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Variable 'simple_rnn_4/kernel:0' shape=(11, 10) dtype=float32, numpy=\n",
            "array([[-0.53254193, -0.4078107 ,  0.44676113,  0.51394254, -0.2948125 ,\n",
            "        -0.07870752,  0.47323114, -0.17033234,  0.19320184, -0.06712741],\n",
            "       [-0.38101283,  0.24090034, -0.39028177, -0.35475966, -0.60926   ,\n",
            "         0.04016956,  0.1721575 ,  0.54529583,  0.5589208 , -0.64409167],\n",
            "       [ 0.43813297,  0.07666479,  0.76040465, -0.03778398,  0.03221209,\n",
            "         0.39558312, -0.14407481, -0.7002811 , -0.7602845 , -0.57358927],\n",
            "       [-0.00356289,  0.2580723 , -0.06978242,  0.7364371 , -0.53311354,\n",
            "         0.23905253, -0.00983143,  0.41220617,  0.17853795, -0.22354172],\n",
            "       [-0.3320076 , -0.25379544,  0.02297579,  0.18417719, -0.22469012,\n",
            "         0.00402836, -0.01638252,  0.04454794, -0.59306574,  0.09959375],\n",
            "       [-0.4436984 ,  0.47046617, -0.3317571 , -0.6511683 , -0.23693936,\n",
            "        -0.11832409,  0.01021892,  0.31412604,  0.1313219 ,  0.04975787],\n",
            "       [ 0.33822572, -0.4569684 , -0.10335898, -0.1202268 , -0.40603384,\n",
            "         0.6207844 ,  0.67047876, -0.6127278 , -0.26481944, -0.16914062],\n",
            "       [-0.5627288 ,  0.01098454, -0.19373941, -0.37995672,  0.25729674,\n",
            "         0.24505149,  0.23489282, -0.05766622,  0.0148505 , -0.139833  ],\n",
            "       [ 0.38107046, -0.3489271 , -0.51319706, -0.22441514, -0.7993609 ,\n",
            "        -0.26192442, -0.34835473, -0.33613372,  0.70834863,  0.6298468 ],\n",
            "       [-0.17880955,  0.18928598, -0.38530245,  0.3571935 , -0.5655833 ,\n",
            "         0.18382813,  0.14940213, -0.3335969 , -0.03882906,  0.09755185],\n",
            "       [-0.14828119,  0.28374425,  0.2681771 , -0.29530993,  0.22293153,\n",
            "        -0.2729535 ,  0.16425808, -0.38672695, -0.5363101 ,  0.3429061 ]],\n",
            "      dtype=float32)>, <tf.Variable 'simple_rnn_4/recurrent_kernel:0' shape=(10, 10) dtype=float32, numpy=\n",
            "array([[-0.05813523,  0.7138873 , -0.21004808, -0.5270044 ,  0.45258114,\n",
            "         0.06179833,  0.37790534,  0.33194223, -0.24948706, -0.6030879 ],\n",
            "       [-0.0910162 ,  0.35968116, -0.62930226, -0.4292743 , -0.18147781,\n",
            "        -0.35874096, -0.08507002, -0.11324559, -0.07860792,  0.37353536],\n",
            "       [ 0.10690499,  0.3310188 , -0.08580469, -0.24858874,  0.29550314,\n",
            "         0.5653807 , -0.3843477 , -0.04852304,  0.5122228 , -0.21866818],\n",
            "       [ 0.23273475,  0.6657219 ,  0.06505226,  0.2844185 , -0.3209633 ,\n",
            "         0.52894765,  0.15450522, -0.02766873, -0.63081384, -0.05188661],\n",
            "       [-0.39494315, -0.2083277 ,  0.41814157,  0.4668859 ,  0.20473716,\n",
            "        -0.3059799 , -0.6574603 ,  0.69458085,  0.1258636 ,  0.6434848 ],\n",
            "       [ 0.15973927,  0.123904  ,  0.09649416, -0.07141068,  0.47909746,\n",
            "         0.05656542,  0.6065482 , -0.0560349 ,  0.18428706,  0.555106  ],\n",
            "       [-0.5058196 ,  0.20887387,  0.7075557 , -0.2901916 , -0.08508392,\n",
            "         0.25454766,  0.27320433, -0.03674944,  0.22691454,  0.1298525 ],\n",
            "       [ 0.3506601 ,  0.01970831,  0.04058372,  0.47473407, -0.51026523,\n",
            "        -0.17950733, -0.00908277,  0.30832452,  0.24520314,  0.03537127],\n",
            "       [ 0.8835249 ,  0.01373827,  0.7932837 ,  0.35335755, -0.29580447,\n",
            "        -0.4212802 , -0.7627255 , -0.26902258, -0.28260243,  0.13580066],\n",
            "       [ 0.22188236, -0.3913973 ,  0.09396461, -0.13525596, -0.18890451,\n",
            "         0.35758278, -0.417615  ,  0.14001137, -0.5504083 , -0.25977892]],\n",
            "      dtype=float32)>, <tf.Variable 'simple_rnn_4/bias:0' shape=(10,) dtype=float32, numpy=\n",
            "array([ 0.2202988 ,  0.01665113, -0.05756198,  0.2246701 , -0.16036431,\n",
            "       -0.11757608,  0.1338003 , -0.17801751,  0.00881385,  0.04237773],\n",
            "      dtype=float32)>, <tf.Variable 'dense_4/kernel:0' shape=(10, 2) dtype=float32, numpy=\n",
            "array([[-0.12949425,  0.29301903],\n",
            "       [ 0.7586384 , -0.97038305],\n",
            "       [-0.62668663,  0.92526335],\n",
            "       [-0.71476525,  0.06231524],\n",
            "       [ 0.10403845, -0.31489033],\n",
            "       [ 0.5037507 ,  0.42399606],\n",
            "       [ 0.99271166, -0.82826966],\n",
            "       [-0.45193428, -0.2864844 ],\n",
            "       [ 0.00396384, -0.35984454],\n",
            "       [-0.580179  , -0.23794532]], dtype=float32)>, <tf.Variable 'dense_4/bias:0' shape=(2,) dtype=float32, numpy=array([-0.05333583,  0.05333577], dtype=float32)>, <tf.Variable 'embedding_4/embeddings:0' shape=(11, 11) dtype=float32, numpy=\n",
            "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLQKKfAtu8Ah",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "baf77997-bfc6-415d-a7ec-3ecb10ca7caa"
      },
      "source": [
        "print(tr_loss)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.0020472244, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}