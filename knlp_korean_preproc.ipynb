{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled24.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moonjune/test-repo/blob/master/knlp_korean_preproc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Euzi89hL1wmH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/e9t/nsmc.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFwwWXCf2XFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "os.chdir('/content/nsmc')\n",
        "!ls\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axbamgwvT3i4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/')\n",
        "!git clone https://github.com/NLP-kr/tensorflow-ml-nlp.git\n",
        "import os\n",
        "os.chdir('/content/tensorflow-ml-nlp')\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7R7qlc-2eQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "%matplotlib inline\n",
        "\n",
        "os.chdir('/content/nsmc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-dvjth2_YmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_IN_PATH = '/content/nsmc/'\n",
        "print(\"파일크기: \")\n",
        "for file in os.listdir(DATA_IN_PATH):\n",
        "  if 'txt'in file:\n",
        "   print(file.ljust(30) + str(round(os.path.getsize(DATA_IN_PATH + file) / 1000000, 2)) + 'MB')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr3t7zTZ_vSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv(DATA_IN_PATH + 'ratings_train.txt', header = 0, delimiter = '\\t', quoting = 3)\n",
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUQi0EWdAMab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('전체 학습 데이터의 개수: {}'.format(len(train_data)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFTbdHd1D1aG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_length = train_data['document'].astype(str).apply(len)\n",
        "train_length.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3g4ehzNEDU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize = (12,5))\n",
        "plt.hist(train_length, bins = 200, alpha = 0.5, color = 'r', label = 'word')\n",
        "plt.yscale('log', nonposy = 'clip')\n",
        "plt.title('Log-Histogram of length of review')\n",
        "plt.xlabel('Length of review')\n",
        "plt.ylabel('Number of review')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eWWLphWEOoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_review = [review for review in train_data['document'] if type(review) is str]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12DbHGfXRY2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordcloud = WordCloud(font_path = DATA_IN_PATH + 'NanumGothic.ttf').generate(' '.join(train_review))\n",
        "\n",
        "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrVeV_RzRpw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axe = plt.subplots(ncols = 1)\n",
        "fig.set_size_inches(6, 3)\n",
        "sns.countplot(train_data['label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-R81PBmWZOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_word_counts = train_data['document'].astype('str').apply(lambda x: len(x.split(' ')))\n",
        "\n",
        "plt.figure(figsize = (15, 10))\n",
        "plt.hist(train_word_counts, bins = 50, facecolor = 'r', label = 'train')\n",
        "plt.title('Log-Hist', fontsize = 15)\n",
        "plt.yscale('log', nonposy = 'clip')\n",
        "plt.legend()\n",
        "plt.xlabel('Num_word', color = 'w')\n",
        "plt.ylabel('Num_review', color = 'w')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnyXFEiIY671",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 전처리\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "from konlpy.tag import Okt\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "DATA_IN_PATH = '/content/nsmc/'\n",
        "\n",
        "train_data = pd.read_csv(DATA_IN_PATH + 'ratings_train.txt', header = 0, delimiter = '\\t', quoting = 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPK9NlMPbplF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data['document'][:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpyCe6FJc-XK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_text = re.sub(\"[^가-힣ㄱ-하-ㅣ\\\\s]\",\"\",train_data['document'][0])\n",
        "print(review_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv8PTGsBgeC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "okt = Okt()\n",
        "review_text = okt.morphs(review_text, stem=True)\n",
        "print(review_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78VFQ75Vg1g6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(['은','는','이','가','하','아','것','들','의','있','되','수','보','주','등','한'])\n",
        "clean_review = [token for token in review_text if not token in stop_words]\n",
        "clean_review"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQQ2oUbNibRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing(review, okt, remove_stopwords = False, stop_words = []):\n",
        "#   함수의 인자는 다음과 같다.\n",
        "#   review: 전처리할 텍스트\n",
        "#   okt: okt 객체를 반복적으로 생성하지 않고 미리 생성한 후 인자로 받는다.\n",
        "#   remove_stopword: 불용어를 제거할지 여부 선택\n",
        "#   stop_word: 불용어 사전은 사용자가 직접 입력해야 함.\n",
        "#   1. 한글 및 공백을 제외한 문자를 모두 제거\n",
        "  review_text = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\",\"\",review)\n",
        "  \n",
        "#   2. okt 객체를 이용해 형태소 단위로 나눈다.\n",
        "  word_review = okt.morphs(review_text, stem= True)\n",
        "  \n",
        "  if remove_stopwords:\n",
        "    word_review = [token for token in word_review if not token in stop_words]\n",
        "  \n",
        "  return word_review"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO6cd9N8kPzx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(['은','는','이','가','하','아','것','들','의','있','되','수','보','주','등','한'])\n",
        "okt = Okt()\n",
        "clean_train_review = []\n",
        "\n",
        "for review in train_data['document']:\n",
        "  # 비어있는 데이터에서 멈추지 않도록 문자열인 경우에만 진행\n",
        "  if type(review) == str:\n",
        "    clean_train_review.append(preprocessing(review, okt, remove_stopwords = True, stop_words = stop_words))\n",
        "  else:\n",
        "    clean_train_review.append([]) # string이 아니면 비어있는 값 추가\n",
        "\n",
        "clean_train_review[:4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsTVapqjk6Ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clean_train_review_csv = pd.DataFrame(clean_train_review)\n",
        "# clean_train_review_csv = clean_train_review_csv.to_csv('/content/nsmc/clean_train_review_csv.csv', encoding='ms949')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L1pOCV0n385",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA1oPvOTmmEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/nsmc/clean_train_review_csv.csv') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwX4cR1mnm7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = pd.read_csv(DATA_IN_PATH + 'ratings_test.txt',header = 0, delimiter = '\\t', quoting = 3)\n",
        "\n",
        "clean_test_review = []\n",
        "\n",
        "for review in test_data['document']:\n",
        "  # 빈 데이터에서 멈추지 않도록 문자열인 경우만 진행\n",
        "  if type(review) == str:\n",
        "    clean_test_review.append(preprocessing(review, okt, remove_stopwords = True, stop_words = stop_words))\n",
        "  else:\n",
        "    clean_test_review.append([]) # string이 아니면 비어있는 값 추가"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu6PCosUqyNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_test_review[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6wQN62prV8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(clean_train_review)\n",
        "train_sequences = tokenizer.texts_to_sequences(clean_train_review)\n",
        "test_sequences = tokenizer.texts_to_sequences(clean_test_review)\n",
        "\n",
        "word_vocab = tokenizer.word_index\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 8\n",
        "\n",
        "train_inputs = pad_sequences(train_sequences, maxlen = MAX_SEQUENCE_LENGTH, padding = 'post')\n",
        "train_labels = np.array(train_data['label'])\n",
        "\n",
        "test_inputs = pad_sequences(test_sequences, maxlen = MAX_SEQUENCE_LENGTH, padding = 'post')\n",
        "test_labels = np.array(test_data['label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCv5xcRmIT8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}