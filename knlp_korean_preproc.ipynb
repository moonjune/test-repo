{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled24.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moonjune/test-repo/blob/master/knlp_korean_preproc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Euzi89hL1wmH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/e9t/nsmc.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFwwWXCf2XFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "os.chdir('/content/nsmc')\n",
        "!ls\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axbamgwvT3i4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/')\n",
        "!git clone https://github.com/NLP-kr/tensorflow-ml-nlp.git\n",
        "import os\n",
        "os.chdir('/content/tensorflow-ml-nlp')\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7R7qlc-2eQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "%matplotlib inline\n",
        "\n",
        "os.chdir('/content/nsmc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-dvjth2_YmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_IN_PATH = '/content/nsmc/'\n",
        "print(\"파일크기: \")\n",
        "for file in os.listdir(DATA_IN_PATH):\n",
        "  if 'txt'in file:\n",
        "   print(file.ljust(30) + str(round(os.path.getsize(DATA_IN_PATH + file) / 1000000, 2)) + 'MB')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr3t7zTZ_vSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv(DATA_IN_PATH + 'ratings_train.txt', header = 0, delimiter = '\\t', quoting = 3)\n",
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUQi0EWdAMab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('전체 학습 데이터의 개수: {}'.format(len(train_data)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFTbdHd1D1aG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_length = train_data['document'].astype(str).apply(len)\n",
        "train_length.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3g4ehzNEDU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize = (12,5))\n",
        "plt.hist(train_length, bins = 200, alpha = 0.5, color = 'r', label = 'word')\n",
        "plt.yscale('log', nonposy = 'clip')\n",
        "plt.title('Log-Histogram of length of review')\n",
        "plt.xlabel('Length of review')\n",
        "plt.ylabel('Number of review')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eWWLphWEOoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_review = [review for review in train_data['document'] if type(review) is str]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12DbHGfXRY2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordcloud = WordCloud(font_path = DATA_IN_PATH + 'NanumGothic.ttf').generate(' '.join(train_review))\n",
        "\n",
        "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrVeV_RzRpw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axe = plt.subplots(ncols = 1)\n",
        "fig.set_size_inches(6, 3)\n",
        "sns.countplot(train_data['label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-R81PBmWZOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_word_counts = train_data['document'].astype('str').apply(lambda x: len(x.split(' ')))\n",
        "\n",
        "plt.figure(figsize = (15, 10))\n",
        "plt.hist(train_word_counts, bins = 50, facecolor = 'r', label = 'train')\n",
        "plt.title('Log-Hist', fontsize = 15)\n",
        "plt.yscale('log', nonposy = 'clip')\n",
        "plt.legend()\n",
        "plt.xlabel('Num_word', color = 'w')\n",
        "plt.ylabel('Num_review', color = 'w')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnyXFEiIY671",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 전처리\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "from konlpy.tag import Okt\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "DATA_IN_PATH = '/content/nsmc/'\n",
        "\n",
        "train_data = pd.read_csv(DATA_IN_PATH + 'ratings_train.txt', header = 0, delimiter = '\\t', quoting = 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPK9NlMPbplF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data['document'][:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpyCe6FJc-XK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_text = re.sub(\"[^가-힣ㄱ-하-ㅣ\\\\s]\",\"\",train_data['document'][0])\n",
        "print(review_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv8PTGsBgeC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "okt = Okt()\n",
        "review_text = okt.morphs(review_text, stem=True)\n",
        "print(review_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78VFQ75Vg1g6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(['은','는','이','가','하','아','것','들','의','있','되','수','보','주','등','한'])\n",
        "clean_review = [token for token in review_text if not token in stop_words]\n",
        "clean_review"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQQ2oUbNibRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing(review, okt, remove_stopwords = False, stop_words = []):\n",
        "#   함수의 인자는 다음과 같다.\n",
        "#   review: 전처리할 텍스트\n",
        "#   okt: okt 객체를 반복적으로 생성하지 않고 미리 생성한 후 인자로 받는다.\n",
        "#   remove_stopword: 불용어를 제거할지 여부 선택\n",
        "#   stop_word: 불용어 사전은 사용자가 직접 입력해야 함.\n",
        "#   1. 한글 및 공백을 제외한 문자를 모두 제거\n",
        "  review_text = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\",\"\",review)\n",
        "  \n",
        "#   2. okt 객체를 이용해 형태소 단위로 나눈다.\n",
        "  word_review = okt.morphs(review_text, stem= True)\n",
        "  \n",
        "  if remove_stopwords:\n",
        "    word_review = [token for token in word_review if not token in stop_words]\n",
        "  \n",
        "  return word_review"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO6cd9N8kPzx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(['은','는','이','가','하','아','것','들','의','있','되','수','보','주','등','한'])\n",
        "okt = Okt()\n",
        "clean_train_review = []\n",
        "\n",
        "for review in train_data['document']:\n",
        "  # 비어있는 데이터에서 멈추지 않도록 문자열인 경우에만 진행\n",
        "  if type(review) == str:\n",
        "    clean_train_review.append(preprocessing(review, okt, remove_stopwords = True, stop_words = stop_words))\n",
        "  else:\n",
        "    clean_train_review.append([]) # string이 아니면 비어있는 값 추가\n",
        "\n",
        "clean_train_review[:4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsTVapqjk6Ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clean_train_review_csv = pd.DataFrame(clean_train_review)\n",
        "# clean_train_review_csv = clean_train_review_csv.to_csv('/content/nsmc/clean_train_review_csv.csv', encoding='ms949')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L1pOCV0n385",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA1oPvOTmmEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/nsmc/clean_train_review_csv.csv') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwX4cR1mnm7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = pd.read_csv(DATA_IN_PATH + 'ratings_test.txt',header = 0, delimiter = '\\t', quoting = 3)\n",
        "\n",
        "clean_test_review = []\n",
        "\n",
        "for review in test_data['document']:\n",
        "  # 빈 데이터에서 멈추지 않도록 문자열인 경우만 진행\n",
        "  if type(review) == str:\n",
        "    clean_test_review.append(preprocessing(review, okt, remove_stopwords = True, stop_words = stop_words))\n",
        "  else:\n",
        "    clean_test_review.append([]) # string이 아니면 비어있는 값 추가"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu6PCosUqyNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_test_review[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6wQN62prV8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(clean_train_review)\n",
        "train_sequences = tokenizer.texts_to_sequences(clean_train_review)\n",
        "test_sequences = tokenizer.texts_to_sequences(clean_test_review)\n",
        "\n",
        "word_vocab = tokenizer.word_index\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 8\n",
        "\n",
        "train_inputs = pad_sequences(train_sequences, maxlen = MAX_SEQUENCE_LENGTH, padding = 'post')\n",
        "train_labels = np.array(train_data['label'])\n",
        "\n",
        "test_inputs = pad_sequences(test_sequences, maxlen = MAX_SEQUENCE_LENGTH, padding = 'post')\n",
        "test_labels = np.array(test_data['label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCv5xcRmIT8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 전처림 저장하기\n",
        "DATA_IN_PATH = '/content/nsmc/'\n",
        "TRAIN_INPUT_DATA = 'nsmc_train_input.npy'\n",
        "TRAIN_LABEL_DATA = 'nsmc_train_label.npy'\n",
        "TEST_INPUT_DATA = 'nsmc_test_input.npy'\n",
        "TEST_LABEL_DATA = 'nsmc_test_label.npy'\n",
        "DATA_CONFIGS = 'data_configs.json'\n",
        "\n",
        "data_configs = {}\n",
        "\n",
        "data_configs['vocab'] = word_vocab\n",
        "data_configs['vocab_size'] = len(word_vocab)+1 \n",
        "\n",
        "import os\n",
        "if not os.path.exists(DATA_IN_PATH):\n",
        "  os.makedirs(DTA_IN_PATH)\n",
        "\n",
        "np.save(open(DATA_IN_PATH + TRAIN_INPUT_DATA, 'wb'), train_inputs)\n",
        "np.save(open(DATA_IN_PATH + TRAIN_LABEL_DATA, 'wb'), train_labels)\n",
        "\n",
        "np.save(open(DATA_IN_PATH + TEST_INPUT_DATA, 'wb'), test_inputs)\n",
        "np.save(open(DATA_IN_PATH + TEST_LABEL_DATA, 'wb'), test_labels)\n",
        "\n",
        "json.dump(data_configs, open(DATA_IN_PATH + DATA_CONFIGS, 'w'), ensure_ascii = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3qn13XBMqmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cnn 방법을 적용할 예정\n",
        "import os\n",
        "from datetime import datetime\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aJGqzTmQ0Zf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_IN_PATH = '/content/nsmc/'\n",
        "DATA_OUT_PATH = '/content/nsmc/data_out/'\n",
        "INPUT_TRAIN_DATA_FILE_NAME = 'nsmc_train_input.npy'\n",
        "LABEL_TRAIN_DATA_FILE_NAME = 'nsmc_train_label.npy'\n",
        "DATA_CONFIGS_FILE_NAME = 'data_configs.json'\n",
        "\n",
        "input_data = np.load(open(DATA_IN_PATH + INPUT_TRAIN_DATA_FILE_NAME, 'rb'))\n",
        "label_data = np.load(open(DATA_IN_PATH + LABEL_TRAIN_DATA_FILE_NAME, 'rb'))\n",
        "prepro_configs = json.load(open(DATA_IN_PATH + DATA_CONFIGS_FILE_NAME, 'r'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp7Hse-yRpNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_SPLIT = 0.1\n",
        "RNG_SEED = 13371447\n",
        "VOCAB_SIZE = prepro_configs['vocab_size']\n",
        "EMB_SIZE = 128\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 1\n",
        "\n",
        "input_train, input_eval, label_train, label_eval = train_test_split(input_data, label_data, test_size = TEST_SPLIT, random_state = RNG_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4k5Wo_rR7Gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mapping_fn(X, Y):\n",
        "  input, label = {'x': X}, Y\n",
        "  return input, label\n",
        "\n",
        "def train_input_fn():\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((input_train, label_train))\n",
        "  dataset = dataset.shuffle(buffer_size = len(input_train))\n",
        "  dataset = dataset.batch(BATCH_SIZE)\n",
        "  dataset = dataset.map(mapping_fn)\n",
        "  dataset = dataset.repeat(count=NUM_EPOCHS)\n",
        "  iterator = dataset.make_one_shot_iterator()\n",
        "  \n",
        "  return iterator.get_next()\n",
        "\n",
        "def eval_input_fn():\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((input_eval, label_eval))\n",
        "  dataset = dataset.shuffle(buffer_size = len(input_eval))\n",
        "  dataset = dataset.batch(16)\n",
        "  dataset = dataset.map(mapping_fn)\n",
        "  iterator = dataset.make_one_shot_iterator()\n",
        "\n",
        "  return iterator.get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzhaGN2nXYA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_fn(features, labels, mode, params):\n",
        "    TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n",
        "    EVAL = mode == tf.estimator.ModeKeys.EVAL\n",
        "    PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n",
        "\n",
        "    embedding_layer = tf.keras.layers.Embedding(\n",
        "                    VOCAB_SIZE,\n",
        "                    EMB_SIZE)(features['x'])\n",
        "\n",
        "    dropout_emb = tf.keras.layers.Dropout(rate = 0.2)(embedding_layer)\n",
        "    \n",
        "    conv = tf.keras.layers.Conv1D(\n",
        "           filters=32,\n",
        "           kernel_size=3,\n",
        "           padding='same',\n",
        "           activation=tf.nn.relu)(dropout_emb)\n",
        "  \n",
        "    pool = tf.keras.layers.GlobalMaxPool1D()(conv)\n",
        "\n",
        "    hidden = tf.keras.layers.Dense(units=250, activation=tf.nn.relu)(pool)   \n",
        "\n",
        "\n",
        "    dropout_hidden = tf.keras.layers.Dropout(rate=0.2)(hidden, training = TRAIN)\n",
        "    logits = tf.keras.layers.Dense(units=1)(dropout_hidden)\n",
        "\n",
        "    if labels is not None:\n",
        "        labels = tf.reshape(labels, [-1, 1])\n",
        "        \n",
        "    if TRAIN:\n",
        "        global_step = tf.train.get_global_step()\n",
        "        loss = tf.losses.sigmoid_cross_entropy(labels, logits)\n",
        "        train_op = tf.train.AdamOptimizer(0.001).minimize(loss, global_step)\n",
        "\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, train_op=train_op, loss = loss)\n",
        "    \n",
        "    elif EVAL:\n",
        "        loss = tf.losses.sigmoid_cross_entropy(labels, logits)\n",
        "        pred = tf.nn.sigmoid(logits)\n",
        "        accuracy = tf.metrics.accuracy(labels, tf.round(pred))\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops={'acc': accuracy})\n",
        "        \n",
        "    elif PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(\n",
        "            mode=mode,\n",
        "            predictions={\n",
        "                'prob': tf.nn.sigmoid(logits),\n",
        "            }\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SubEgGehXe-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "est = tf.estimator.Estimator(model_fn, model_dir=\"data_out/checkpoint/cnn_model\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLhEeHEIXhjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_start = datetime.utcnow()\n",
        "print(\"Experiment started at {}\".format(time_start.strftime(\"%H:%M:%S\")))\n",
        "print(\".......................................\") \n",
        "\n",
        "est.train(train_input_fn)\n",
        "\n",
        "time_end = datetime.utcnow()\n",
        "print(\".......................................\")\n",
        "print(\"Experiment finished at {}\".format(time_end.strftime(\"%H:%M:%S\")))\n",
        "print(\"\")\n",
        "time_elapsed = time_end - time_start\n",
        "print(\"Experiment elapsed time: {} seconds\".format(time_elapsed.total_seconds()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MITydAb-Ydri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid = est.evaluate(eval_input_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3lgQutaYeLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_TEST_DATA = 'nsmc_test_input.npy'\n",
        "LABEL_TEST_DATA = 'nsmc_test_label.npy'\n",
        "\n",
        "test_input_data = np.load(open(DATA_IN_PATH + INPUT_TEST_DATA, 'rb'))\n",
        "test_label_data = np.load(open(DATA_IN_PATH + LABEL_TEST_DATA, 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SODMLqgcYgeE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_input_fn():\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((test_input_data, test_label_data))\n",
        "    dataset = dataset.batch(16)\n",
        "    dataset = dataset.map(mapping_fn)\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    \n",
        "    return iterator.get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J69TF2_qYivy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict = est.evaluate(test_input_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8wbvif-lkWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzyG5Uu_loE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb20yrlilqtQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}